训练时间: 20250530_192139
全局类别分布: {0: 47, 1: 130}
===========================

模型架构:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 399, 12)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 399, 16)      6144        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 399, 16)      64          conv1d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 399, 16)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 399, 11)      5632        re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 399, 11)      44          conv1d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 399, 11)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 399, 11)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 399, 11)      3872        dropout[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 399, 11)      176         re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 399, 11)      44          conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 399, 11)      44          conv1d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 399, 11)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 399, 11)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 399, 11)      0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 399, 11)      0           re_lu_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 399, 11)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 399, 11)      3872        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 399, 11)      44          conv1d_4[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 399, 11)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 399, 11)      0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 399, 11)      3872        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 399, 11)      44          conv1d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 399, 11)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 399, 11)      0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 399, 11)      0           re_lu_4[0][0]                    
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 399, 11)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 399, 11)      3872        re_lu_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 399, 11)      44          conv1d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 399, 11)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 399, 11)      0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 399, 11)      3872        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 399, 11)      44          conv1d_7[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 399, 11)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 399, 11)      0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 399, 11)      0           re_lu_7[0][0]                    
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 399, 11)      0           add_2[0][0]                      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4389)         0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            8780        flatten[0][0]                    
==================================================================================================
Total params: 40,464
Trainable params: 40,278
Non-trainable params: 186
__________________________________________________________________________________________________
===========================

第 1 折训练集分布: {0: 33, 1: 33}
第 1 折验证集分布: {0: 11, 1: 11}


=== 第 1 折 评估结果 ===
第 1 折 AUC: 0.5289
第 1 折 混淆矩阵:
[[5 6]
 [4 7]]
第 1 折 分类报告:
              precision    recall  f1-score   support

           0       0.56      0.45      0.50        11
           1       0.54      0.64      0.58        11

    accuracy                           0.55        22
   macro avg       0.55      0.55      0.54        22
weighted avg       0.55      0.55      0.54        22

AUC: 0.5289
===========================

第 2 折训练集分布: {0: 33, 1: 33}
第 2 折验证集分布: {0: 11, 1: 11}


=== 第 2 折 评估结果 ===
第 2 折 AUC: 0.4959
第 2 折 混淆矩阵:
[[6 5]
 [6 5]]
第 2 折 分类报告:
              precision    recall  f1-score   support

           0       0.50      0.55      0.52        11
           1       0.50      0.45      0.48        11

    accuracy                           0.50        22
   macro avg       0.50      0.50      0.50        22
weighted avg       0.50      0.50      0.50        22

AUC: 0.4959
===========================

第 3 折训练集分布: {0: 33, 1: 33}
第 3 折验证集分布: {0: 11, 1: 11}


=== 第 3 折 评估结果 ===
第 3 折 AUC: 0.6281
第 3 折 混淆矩阵:
[[ 3  8]
 [ 1 10]]
第 3 折 分类报告:
              precision    recall  f1-score   support

           0       0.75      0.27      0.40        11
           1       0.56      0.91      0.69        11

    accuracy                           0.59        22
   macro avg       0.65      0.59      0.54        22
weighted avg       0.65      0.59      0.54        22

AUC: 0.6281
===========================

第 4 折训练集分布: {0: 33, 1: 33}
第 4 折验证集分布: {0: 11, 1: 11}


=== 第 4 折 评估结果 ===
第 4 折 AUC: 0.4959
第 4 折 混淆矩阵:
[[6 5]
 [7 4]]
第 4 折 分类报告:
              precision    recall  f1-score   support

           0       0.46      0.55      0.50        11
           1       0.44      0.36      0.40        11

    accuracy                           0.45        22
   macro avg       0.45      0.45      0.45        22
weighted avg       0.45      0.45      0.45        22

AUC: 0.4959
===========================

平均混淆矩阵:
[[5.  6. ]
 [4.5 6.5]]
===========================

超参数配置:
data_dir = raw_data
labels_file = labels.csv
Kt = 32
pt = 0.3
Ft = 11
num_classes = 2
batch_size = 16
epochs = 50
learning_rate = 0.001
patience_es = 8
patience_lr = 10
factor_lr = 0.5
min_lr = 1e-06
n_splits = 4
random_state = 42
===========================
