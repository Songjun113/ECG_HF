训练时间: 20250530_181101
全局类别分布: {0: 47, 1: 130}
===========================

模型架构:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 399, 12)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 399, 2)       264         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 399, 2)       8           conv1d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 399, 2)       0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 399, 11)      242         re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 399, 11)      44          conv1d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 399, 11)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 399, 11)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 399, 11)      1331        dropout[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 399, 11)      22          re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 399, 11)      44          conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 399, 11)      44          conv1d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 399, 11)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 399, 11)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 399, 11)      0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 399, 11)      0           re_lu_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 399, 11)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 399, 11)      1331        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 399, 11)      44          conv1d_4[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 399, 11)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 399, 11)      0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 399, 11)      1331        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 399, 11)      44          conv1d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 399, 11)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 399, 11)      0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 399, 11)      0           re_lu_4[0][0]                    
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 399, 11)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 399, 11)      1331        re_lu_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 399, 11)      44          conv1d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 399, 11)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 399, 11)      0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 399, 11)      1331        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 399, 11)      44          conv1d_7[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 399, 11)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 399, 11)      0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 399, 11)      0           re_lu_7[0][0]                    
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 399, 11)      0           add_2[0][0]                      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4389)         0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            8780        flatten[0][0]                    
==================================================================================================
Total params: 16,279
Trainable params: 16,121
Non-trainable params: 158
__________________________________________________________________________________________________
===========================

第 1 折训练前标签分布（训练集）: {0: 44, 1: 121}


=== 第 1 折 评估结果 ===
第 1 折 AUC: 0.3333
第 1 折 混淆矩阵:
[[0 3]
 [0 9]]
第 1 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12

AUC: 0.3333
===========================

第 2 折训练前标签分布（训练集）: {0: 45, 1: 121}


=== 第 2 折 评估结果 ===
第 2 折 AUC: 0.2222
第 2 折 混淆矩阵:
[[0 2]
 [0 9]]
第 2 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.82      1.00      0.90         9

    accuracy                           0.82        11
   macro avg       0.41      0.50      0.45        11
weighted avg       0.67      0.82      0.74        11

AUC: 0.2222
===========================

第 3 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 3 折 评估结果 ===
第 3 折 AUC: 0.5833
第 3 折 混淆矩阵:
[[2 1]
 [4 4]]
第 3 折 分类报告:
              precision    recall  f1-score   support

           0       0.33      0.67      0.44         3
           1       0.80      0.50      0.62         8

    accuracy                           0.55        11
   macro avg       0.57      0.58      0.53        11
weighted avg       0.67      0.55      0.57        11

AUC: 0.5833
===========================

第 4 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 4 折 评估结果 ===
第 4 折 AUC: 0.1667
第 4 折 混淆矩阵:
[[0 3]
 [0 8]]
第 4 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.1667
===========================

第 5 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 5 折 评估结果 ===
第 5 折 AUC: 0.6667
第 5 折 混淆矩阵:
[[2 1]
 [1 7]]
第 5 折 分类报告:
              precision    recall  f1-score   support

           0       0.67      0.67      0.67         3
           1       0.88      0.88      0.88         8

    accuracy                           0.82        11
   macro avg       0.77      0.77      0.77        11
weighted avg       0.82      0.82      0.82        11

AUC: 0.6667
===========================

第 6 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 6 折 评估结果 ===
第 6 折 AUC: 0.9167
第 6 折 混淆矩阵:
[[0 3]
 [0 8]]
第 6 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.9167
===========================

第 7 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 7 折 评估结果 ===
第 7 折 AUC: 0.3333
第 7 折 混淆矩阵:
[[0 3]
 [0 8]]
第 7 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.3333
===========================

第 8 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 8 折 评估结果 ===
第 8 折 AUC: 0.7083
第 8 折 混淆矩阵:
[[1 2]
 [2 6]]
第 8 折 分类报告:
              precision    recall  f1-score   support

           0       0.33      0.33      0.33         3
           1       0.75      0.75      0.75         8

    accuracy                           0.64        11
   macro avg       0.54      0.54      0.54        11
weighted avg       0.64      0.64      0.64        11

AUC: 0.7083
===========================

第 9 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 9 折 评估结果 ===
第 9 折 AUC: 0.3333
第 9 折 混淆矩阵:
[[0 3]
 [0 8]]
第 9 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.3333
===========================

第 10 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 10 折 评估结果 ===
第 10 折 AUC: 0.7917
第 10 折 混淆矩阵:
[[0 3]
 [0 8]]
第 10 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.7917
===========================

第 11 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 11 折 评估结果 ===
第 11 折 AUC: 0.4167
第 11 折 混淆矩阵:
[[0 3]
 [0 8]]
第 11 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.4167
===========================

第 12 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 12 折 评估结果 ===
第 12 折 AUC: 0.9167
第 12 折 混淆矩阵:
[[0 3]
 [0 8]]
第 12 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.9167
===========================

第 13 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 13 折 评估结果 ===
第 13 折 AUC: 0.8750
第 13 折 混淆矩阵:
[[0 3]
 [0 8]]
第 13 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.8750
===========================

第 14 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 14 折 评估结果 ===
第 14 折 AUC: 0.5833
第 14 折 混淆矩阵:
[[1 2]
 [0 8]]
第 14 折 分类报告:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50         3
           1       0.80      1.00      0.89         8

    accuracy                           0.82        11
   macro avg       0.90      0.67      0.69        11
weighted avg       0.85      0.82      0.78        11

AUC: 0.5833
===========================

第 15 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 15 折 评估结果 ===
第 15 折 AUC: 0.4167
第 15 折 混淆矩阵:
[[0 3]
 [0 8]]
第 15 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.4167
===========================

第 16 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 16 折 评估结果 ===
第 16 折 AUC: 0.5833
第 16 折 混淆矩阵:
[[0 3]
 [0 8]]
第 16 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.5833
===========================

平均混淆矩阵:
[[0.375  2.5625]
 [0.4375 7.6875]]
===========================

超参数配置:
data_dir = raw_data
labels_file = labels.csv
Kt = 11
pt = 0.3
Ft = 11
num_classes = 2
batch_size = 32
epochs = 50
learning_rate = 0.001
patience_es = 8
patience_lr = 5
factor_lr = 0.3
min_lr = 1e-06
n_splits = 16
random_state = 42
===========================
