训练时间: 20250530_180457
全局类别分布: {0: 47, 1: 130}
===========================

模型架构:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 399, 12)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 399, 2)       264         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 399, 2)       8           conv1d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 399, 2)       0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 399, 11)      242         re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 399, 11)      44          conv1d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 399, 11)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 399, 11)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 399, 11)      1331        dropout[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 399, 11)      22          re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 399, 11)      44          conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 399, 11)      44          conv1d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 399, 11)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 399, 11)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 399, 11)      0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 399, 11)      0           re_lu_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 399, 11)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 399, 11)      1331        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 399, 11)      44          conv1d_4[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 399, 11)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 399, 11)      0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 399, 11)      1331        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 399, 11)      44          conv1d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 399, 11)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 399, 11)      0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 399, 11)      0           re_lu_4[0][0]                    
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 399, 11)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 399, 11)      1331        re_lu_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 399, 11)      44          conv1d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 399, 11)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 399, 11)      0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 399, 11)      1331        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 399, 11)      44          conv1d_7[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 399, 11)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 399, 11)      0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 399, 11)      0           re_lu_7[0][0]                    
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 399, 11)      0           add_2[0][0]                      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4389)         0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            8780        flatten[0][0]                    
==================================================================================================
Total params: 16,279
Trainable params: 16,121
Non-trainable params: 158
__________________________________________________________________________________________________
===========================

第 1 折训练前标签分布（训练集）: {0: 44, 1: 121}


=== 第 1 折 评估结果 ===
第 1 折 AUC: 0.6667
第 1 折 混淆矩阵:
[[1 2]
 [0 9]]
第 1 折 分类报告:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50         3
           1       0.82      1.00      0.90         9

    accuracy                           0.83        12
   macro avg       0.91      0.67      0.70        12
weighted avg       0.86      0.83      0.80        12

AUC: 0.6667
===========================

第 2 折训练前标签分布（训练集）: {0: 45, 1: 121}


=== 第 2 折 评估结果 ===
第 2 折 AUC: 0.3333
第 2 折 混淆矩阵:
[[0 2]
 [0 9]]
第 2 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.82      1.00      0.90         9

    accuracy                           0.82        11
   macro avg       0.41      0.50      0.45        11
weighted avg       0.67      0.82      0.74        11

AUC: 0.3333
===========================

第 3 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 3 折 评估结果 ===
第 3 折 AUC: 0.7083
第 3 折 混淆矩阵:
[[0 3]
 [0 8]]
第 3 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.7083
===========================

第 4 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 4 折 评估结果 ===
第 4 折 AUC: 0.5000
第 4 折 混淆矩阵:
[[0 3]
 [0 8]]
第 4 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.5000
===========================

第 5 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 5 折 评估结果 ===
第 5 折 AUC: 0.5833
第 5 折 混淆矩阵:
[[0 3]
 [2 6]]
第 5 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      0.75      0.71         8

    accuracy                           0.55        11
   macro avg       0.33      0.38      0.35        11
weighted avg       0.48      0.55      0.51        11

AUC: 0.5833
===========================

第 6 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 6 折 评估结果 ===
第 6 折 AUC: 0.7917
第 6 折 混淆矩阵:
[[0 3]
 [0 8]]
第 6 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.7917
===========================

第 7 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 7 折 评估结果 ===
第 7 折 AUC: 0.2500
第 7 折 混淆矩阵:
[[0 3]
 [0 8]]
第 7 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.2500
===========================

第 8 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 8 折 评估结果 ===
第 8 折 AUC: 0.4167
第 8 折 混淆矩阵:
[[0 3]
 [2 6]]
第 8 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.67      0.75      0.71         8

    accuracy                           0.55        11
   macro avg       0.33      0.38      0.35        11
weighted avg       0.48      0.55      0.51        11

AUC: 0.4167
===========================

第 9 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 9 折 评估结果 ===
第 9 折 AUC: 0.5833
第 9 折 混淆矩阵:
[[1 2]
 [1 7]]
第 9 折 分类报告:
              precision    recall  f1-score   support

           0       0.50      0.33      0.40         3
           1       0.78      0.88      0.82         8

    accuracy                           0.73        11
   macro avg       0.64      0.60      0.61        11
weighted avg       0.70      0.73      0.71        11

AUC: 0.5833
===========================

第 10 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 10 折 评估结果 ===
第 10 折 AUC: 0.7917
第 10 折 混淆矩阵:
[[0 3]
 [0 8]]
第 10 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.7917
===========================

第 11 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 11 折 评估结果 ===
第 11 折 AUC: 0.5833
第 11 折 混淆矩阵:
[[0 3]
 [0 8]]
第 11 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.5833
===========================

第 12 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 12 折 评估结果 ===
第 12 折 AUC: 0.5833
第 12 折 混淆矩阵:
[[0 3]
 [0 8]]
第 12 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.5833
===========================

第 13 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 13 折 评估结果 ===
第 13 折 AUC: 0.2083
第 13 折 混淆矩阵:
[[0 3]
 [0 8]]
第 13 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.2083
===========================

第 14 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 14 折 评估结果 ===
第 14 折 AUC: 0.6250
第 14 折 混淆矩阵:
[[2 1]
 [6 2]]
第 14 折 分类报告:
              precision    recall  f1-score   support

           0       0.25      0.67      0.36         3
           1       0.67      0.25      0.36         8

    accuracy                           0.36        11
   macro avg       0.46      0.46      0.36        11
weighted avg       0.55      0.36      0.36        11

AUC: 0.6250
===========================

第 15 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 15 折 评估结果 ===
第 15 折 AUC: 0.7500
第 15 折 混淆矩阵:
[[0 3]
 [0 8]]
第 15 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.7500
===========================

第 16 折训练前标签分布（训练集）: {0: 44, 1: 122}


=== 第 16 折 评估结果 ===
第 16 折 AUC: 0.3750
第 16 折 混淆矩阵:
[[0 3]
 [0 8]]
第 16 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.73      1.00      0.84         8

    accuracy                           0.73        11
   macro avg       0.36      0.50      0.42        11
weighted avg       0.53      0.73      0.61        11

AUC: 0.3750
===========================

平均混淆矩阵:
[[0.25   2.6875]
 [0.6875 7.4375]]
===========================

超参数配置:
data_dir = raw_data
labels_file = labels.csv
Kt = 11
pt = 0.3
Ft = 11
num_classes = 2
batch_size = 32
epochs = 50
learning_rate = 0.001
patience_es = 8
patience_lr = 5
factor_lr = 0.3
min_lr = 1e-06
n_splits = 16
random_state = 42
===========================
