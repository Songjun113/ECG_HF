训练时间: 20250530_181241
全局类别分布: {0: 47, 1: 130}
===========================

模型架构:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 399, 12)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 399, 2)       264         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 399, 2)       8           conv1d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 399, 2)       0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 399, 11)      242         re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 399, 11)      44          conv1d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 399, 11)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 399, 11)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 399, 11)      1331        dropout[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 399, 11)      22          re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 399, 11)      44          conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 399, 11)      44          conv1d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 399, 11)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 399, 11)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 399, 11)      0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 399, 11)      0           re_lu_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 399, 11)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 399, 11)      1331        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 399, 11)      44          conv1d_4[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 399, 11)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 399, 11)      0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 399, 11)      1331        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 399, 11)      44          conv1d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 399, 11)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 399, 11)      0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 399, 11)      0           re_lu_4[0][0]                    
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 399, 11)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 399, 11)      1331        re_lu_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 399, 11)      44          conv1d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 399, 11)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 399, 11)      0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 399, 11)      1331        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 399, 11)      44          conv1d_7[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 399, 11)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 399, 11)      0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 399, 11)      0           re_lu_7[0][0]                    
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 399, 11)      0           add_2[0][0]                      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4389)         0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            8780        flatten[0][0]                    
==================================================================================================
Total params: 16,279
Trainable params: 16,121
Non-trainable params: 158
__________________________________________________________________________________________________
===========================

第 1 折训练前标签分布（训练集）: {0: 35, 1: 97}


=== 第 1 折 评估结果 ===
第 1 折 AUC: 0.3611
第 1 折 混淆矩阵:
[[ 0 12]
 [ 0 33]]
第 1 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.73      1.00      0.85        33

    accuracy                           0.73        45
   macro avg       0.37      0.50      0.42        45
weighted avg       0.54      0.73      0.62        45

AUC: 0.3611
===========================

第 2 折训练前标签分布（训练集）: {0: 36, 1: 97}


=== 第 2 折 评估结果 ===
第 2 折 AUC: 0.7025
第 2 折 混淆矩阵:
[[ 0 11]
 [ 0 33]]
第 2 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        11
           1       0.75      1.00      0.86        33

    accuracy                           0.75        44
   macro avg       0.38      0.50      0.43        44
weighted avg       0.56      0.75      0.64        44

AUC: 0.7025
===========================

第 3 折训练前标签分布（训练集）: {0: 35, 1: 98}


=== 第 3 折 评估结果 ===
第 3 折 AUC: 0.3437
第 3 折 混淆矩阵:
[[ 0 12]
 [ 1 31]]
第 3 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.72      0.97      0.83        32

    accuracy                           0.70        44
   macro avg       0.36      0.48      0.41        44
weighted avg       0.52      0.70      0.60        44

AUC: 0.3437
===========================

第 4 折训练前标签分布（训练集）: {0: 35, 1: 98}


=== 第 4 折 评估结果 ===
第 4 折 AUC: 0.5885
第 4 折 混淆矩阵:
[[ 0 12]
 [ 0 32]]
第 4 折 分类报告:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.73      1.00      0.84        32

    accuracy                           0.73        44
   macro avg       0.36      0.50      0.42        44
weighted avg       0.53      0.73      0.61        44

AUC: 0.5885
===========================

平均混淆矩阵:
[[ 0.   11.75]
 [ 0.25 32.25]]
===========================

超参数配置:
data_dir = raw_data
labels_file = labels.csv
Kt = 11
pt = 0.3
Ft = 11
num_classes = 2
batch_size = 16
epochs = 50
learning_rate = 0.001
patience_es = 8
patience_lr = 5
factor_lr = 0.3
min_lr = 1e-06
n_splits = 4
random_state = 42
===========================
