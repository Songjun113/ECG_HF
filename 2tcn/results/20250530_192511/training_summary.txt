训练时间: 20250530_192511
全局类别分布: {0: 47, 1: 130}
===========================

模型架构:
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 399, 12)]    0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 399, 16)      6144        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 399, 16)      64          conv1d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 399, 16)      0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 399, 11)      5632        re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 399, 11)      44          conv1d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 399, 11)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 399, 11)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 399, 11)      3872        dropout[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 399, 11)      176         re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 399, 11)      44          conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 399, 11)      44          conv1d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 399, 11)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 399, 11)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 399, 11)      0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
add (Add)                       (None, 399, 11)      0           re_lu_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 399, 11)      0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 399, 11)      3872        re_lu_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 399, 11)      44          conv1d_4[0][0]                   
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 399, 11)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 399, 11)      0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 399, 11)      3872        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 399, 11)      44          conv1d_5[0][0]                   
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 399, 11)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 399, 11)      0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 399, 11)      0           re_lu_4[0][0]                    
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 399, 11)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 399, 11)      3872        re_lu_7[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 399, 11)      44          conv1d_6[0][0]                   
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 399, 11)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 399, 11)      0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 399, 11)      3872        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 399, 11)      44          conv1d_7[0][0]                   
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 399, 11)      0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 399, 11)      0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
add_2 (Add)                     (None, 399, 11)      0           re_lu_7[0][0]                    
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 399, 11)      0           add_2[0][0]                      
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4389)         0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            8780        flatten[0][0]                    
==================================================================================================
Total params: 40,464
Trainable params: 40,278
Non-trainable params: 186
__________________________________________________________________________________________________
===========================

第 1 折训练集分布: {0: 30, 1: 30}
第 1 折验证集分布: {0: 15, 1: 15}


=== 第 1 折 评估结果 ===
第 1 折 AUC: 0.4533
第 1 折 混淆矩阵:
[[12  3]
 [13  2]]
第 1 折 分类报告:
              precision    recall  f1-score   support

           0       0.48      0.80      0.60        15
           1       0.40      0.13      0.20        15

    accuracy                           0.47        30
   macro avg       0.44      0.47      0.40        30
weighted avg       0.44      0.47      0.40        30

AUC: 0.4533
===========================

第 2 折训练集分布: {0: 30, 1: 30}
第 2 折验证集分布: {0: 15, 1: 15}


=== 第 2 折 评估结果 ===
第 2 折 AUC: 0.7289
第 2 折 混淆矩阵:
[[15  0]
 [14  1]]
第 2 折 分类报告:
              precision    recall  f1-score   support

           0       0.52      1.00      0.68        15
           1       1.00      0.07      0.12        15

    accuracy                           0.53        30
   macro avg       0.76      0.53      0.40        30
weighted avg       0.76      0.53      0.40        30

AUC: 0.7289
===========================

第 3 折训练集分布: {0: 30, 1: 30}
第 3 折验证集分布: {0: 15, 1: 15}


=== 第 3 折 评估结果 ===
第 3 折 AUC: 0.5111
第 3 折 混淆矩阵:
[[7 8]
 [7 8]]
第 3 折 分类报告:
              precision    recall  f1-score   support

           0       0.50      0.47      0.48        15
           1       0.50      0.53      0.52        15

    accuracy                           0.50        30
   macro avg       0.50      0.50      0.50        30
weighted avg       0.50      0.50      0.50        30

AUC: 0.5111
===========================

平均混淆矩阵:
[[11.33333333  3.66666667]
 [11.33333333  3.66666667]]
===========================

超参数配置:
data_dir = raw_data
labels_file = labels.csv
Kt = 32
pt = 0.3
Ft = 11
num_classes = 2
batch_size = 16
epochs = 50
learning_rate = 0.001
patience_es = 8
patience_lr = 10
factor_lr = 0.9
min_lr = 1e-06
n_splits = 3
random_state = 42
===========================
